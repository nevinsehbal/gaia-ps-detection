{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m---------------- Dataset information: ----------------\u001b[0m\n",
      "\u001b[96m[I] Sample rate: 100 Hz\u001b[0m\n",
      "\u001b[96m[I] Chosen window size:900\u001b[0m\n",
      "\u001b[96m[I] Hopping size:300\u001b[0m\n",
      "\u001b[96m[I] Each sample is window_size/sample rate seconds long. Each sample has 3 channels.\u001b[0m\n",
      "\u001b[96m[I] Dataset values shape is: [num_samples, num_window, num_channel, (height) 1, (width) num_sample_points]\u001b[0m\n",
      "\u001b[96m[I] Dataset value shape: torch.Size([1575, 3, 3, 1, 900])\u001b[0m\n",
      "\u001b[96m[I] Dataset labels shape is: [num_samples, 4], where the 4 values are [p_idx, s_idx, no_PS, only_P, only_S, both_PS]\u001b[0m\n",
      "\u001b[96m[I] Dataset label shape:torch.Size([4725, 6])\u001b[0m\n",
      "\u001b[96m[I] One sample shape: torch.Size([3, 3, 1, 900])\u001b[0m\n",
      "\u001b[96m[I] One label shape: torch.Size([6])\u001b[0m\n",
      "\u001b[96m[I] ----------------------------------------------------\u001b[0m\n",
      "\u001b[96m[I] Some label examples in the dataset:\u001b[0m\n",
      "\u001b[96m[I] Label: tensor([-1., -1.,  1.,  0.,  0.,  0.])\u001b[0m\n",
      "\u001b[96m[I] Label: tensor([894.,  -1.,   0.,   1.,   0.,   0.])\u001b[0m\n",
      "\u001b[96m[I] Label: tensor([359., 953.,   0.,   0.,   0.,   1.])\u001b[0m\n",
      "\u001b[96m[I] Label: tensor([    1286.,       -1.,        0.,        1.,        0.,        0.])\u001b[0m\n",
      "\u001b[92m[S] --------------------------\n",
      "Dataloaders are created.\u001b[0m\n",
      "\u001b[92m[S] Train dataloader size:1264\u001b[0m\n",
      "\u001b[92m[S] Validation dataloader size:160\u001b[0m\n",
      "\u001b[92m[S] Test dataloader size:158\u001b[0m\n",
      "\u001b[92m[S] --------------------------\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from convlstm import SeismicConvLSTM\n",
    "from customLoss import CustomLoss\n",
    "import torch\n",
    "from dataloader import train_dataloader, val_dataloader, test_dataloader\n",
    "from evaluater import evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "Layer 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SeismicConvLSTM:\n\tsize mismatch for convlstm.cell_list.0.conv.weight: copying a param with shape torch.Size([256, 67, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 67, 11, 1]).\n\tsize mismatch for convlstm.cell_list.1.conv.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 5, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# load the model from the saved file\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_20241008-2306_epoch30_lr0.01_lambda2_windows3_datapoints900.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SeismicConvLSTM:\n\tsize mismatch for convlstm.cell_list.0.conv.weight: copying a param with shape torch.Size([256, 67, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 67, 11, 1]).\n\tsize mismatch for convlstm.cell_list.1.conv.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 5, 1])."
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "# We are dynamically fetching the input channels, num_windows, data_points_of_each_window, and the output_dim from the dataset using the dataloader\n",
    "one_sample = next(iter(train_dataloader)) # one_sample[0].shape, one_sample[1].shape --> torch.Size([16, 3, 3, 1, 900]) torch.Size([16, 4])\n",
    "INPUT_CHANNELS = one_sample[0].shape[2] # one_sample[0].shape[2] --> 3\n",
    "OUTPUT_DIM = one_sample[1].shape[1] # one_sample[1].shape[1] --> 4\n",
    "NUM_WINDOWS = one_sample[0].shape[1] # one_sample[0].shape[1] --> 3\n",
    "DATA_POINTS_OF_EACH_WINDOW = one_sample[0].shape[4] # one_sample[0].shape[4] --> 900\n",
    "HIDDEN_DIM = [32, 32, 64, 64, 128]\n",
    "KERNEL_SIZE = (11, 5, 3, 3, 3)    \n",
    "NUM_CONVLSTM_BLOCKS = 5\n",
    "model = SeismicConvLSTM(input_dim=INPUT_CHANNELS, hidden_dim=HIDDEN_DIM, kernel_size=KERNEL_SIZE, num_layers=NUM_CONVLSTM_BLOCKS, output_dim=OUTPUT_DIM, num_windows = NUM_WINDOWS, data_points = DATA_POINTS_OF_EACH_WINDOW)\n",
    "# load the model from the saved file\n",
    "model_name = \"model_20241008-2306_epoch30_lr0.01_lambda2_windows3_datapoints900.pth\"\n",
    "model.load_state_dict(torch.load('models/'+model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with the test dataloader\n",
    "criterion = CustomLoss(lambda_val=2)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "output_path  = 'output/'+model_name.split('.')[0]+'_test'\n",
    "evaluate_model(model, test_dataloader, criterion, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_time_predictions(data_loader, model, device):\n",
    "    \"\"\" Collect true and predicted P and S wave times from a DataLoader using the given model. \"\"\"\n",
    "    model.eval()\n",
    "    print(\"Evaluation startedd...\")\n",
    "    true_times = []\n",
    "    pred_times = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            p_orig, s_orig, no_ps_orig, only_p_orig, only_s_orig, both_ps_orig = labels[0]\n",
    "            p_pred, s_pred, no_ps, only_p, only_s, both_ps = outputs[0]\n",
    "        \n",
    "            true_times.append((p_orig, s_orig))\n",
    "            pred_times.append((p_pred, s_pred))\n",
    "    print(\"Evaluation completed.\")\n",
    "    # true_times, pred_times = [], []\n",
    "    # with torch.no_grad():\n",
    "    #     for samples, p_times, s_times, _ in data_loader:\n",
    "    #         samples = samples.to(device)\n",
    "    #         p_pred, s_pred, _ = model(samples)\n",
    "    #         true_times.append((p_times.cpu(), s_times.cpu()))\n",
    "    #         pred_times.append((p_pred.cpu(), s_pred.cpu()))\n",
    "    return true_times, pred_times\n",
    "\n",
    "def flatten_and_convert(data_list):\n",
    "    \"\"\" Flatten each array in the list and convert tensors to numpy arrays if needed. \"\"\"\n",
    "    return [data.numpy().flatten() if isinstance(data, torch.Tensor) else np.array(data).flatten()\n",
    "            for data_tuple in data_list for data in data_tuple]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Collect data for train, validation, and test sets\n",
    "train_true_times, train_pred_times = collect_time_predictions(train_dataloader, model, device='cpu')\n",
    "val_true_times, val_pred_times = collect_time_predictions(val_dataloader, model, device='cpu')\n",
    "test_true_times, test_pred_times = collect_time_predictions(test_dataloader, model, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Unpack and flatten the true and predicted times for P and S waves\n",
    "# p_times_true_train_flat = flatten_and_convert([times[0] for times in train_true_times])\n",
    "# s_times_true_train_flat = flatten_and_convert([times[1] for times in train_true_times])\n",
    "# p_times_pred_train_flat = flatten_and_convert([times[0] for times in train_pred_times])\n",
    "# s_times_pred_train_flat = flatten_and_convert([times[1] for times in train_pred_times])\n",
    "\n",
    "# p_times_true_val_flat = []\n",
    "# s_times_true_val_flat = []\n",
    "# p_times_pred_val_flat = []\n",
    "# s_times_pred_val_flat = []\n",
    "\n",
    "# p_times_true_test_flat = []\n",
    "# s_times_true_test_flat = []\n",
    "# p_times_pred_test_flat = []\n",
    "# s_times_pred_test_flat = []\n",
    "\n",
    "# for i in val_true_times:\n",
    "#     p_times_true_val_flat.append(i[0].numpy().flatten())\n",
    "#     s_times_true_val_flat.append(i[1].numpy().flatten())\n",
    "# for i in val_pred_times:\n",
    "#     p_times_pred_val_flat.append(i[0].numpy().flatten())\n",
    "#     s_times_pred_val_flat.append(i[1].numpy().flatten())   \n",
    "# for i in test_true_times:\n",
    "#     p_times_true_test_flat.append(i[0].numpy().flatten())\n",
    "#     s_times_true_test_flat.append(i[1].numpy().flatten())\n",
    "# for i in test_pred_times:\n",
    "#     p_times_pred_test_flat.append(i[0].numpy().flatten())\n",
    "#     s_times_pred_test_flat.append(i[1].numpy().flatten())\n",
    "\n",
    "def flatten_and_convert(data_list):\n",
    "    \"\"\" Flatten each array in the list and convert tensors to numpy arrays if needed. \"\"\"\n",
    "    return [data.item() if isinstance(data, torch.Tensor) else data.flatten().item()\n",
    "            for data_tuple in data_list for data in data_tuple]\n",
    "\n",
    "p_times_true_train_flat = flatten_and_convert([(times[0],) for times in train_true_times])\n",
    "s_times_true_train_flat = flatten_and_convert([(times[1],) for times in train_true_times])\n",
    "p_times_pred_train_flat = flatten_and_convert([(times[0],) for times in train_pred_times])\n",
    "s_times_pred_train_flat = flatten_and_convert([(times[1],) for times in train_pred_times])\n",
    "\n",
    "p_times_true_val_flat = flatten_and_convert([(times[0],) for times in val_true_times])\n",
    "s_times_true_val_flat = flatten_and_convert([(times[1],) for times in val_true_times])\n",
    "p_times_pred_val_flat = flatten_and_convert([(times[0],) for times in val_pred_times])\n",
    "s_times_pred_val_flat = flatten_and_convert([(times[1],) for times in val_pred_times])\n",
    "\n",
    "p_times_true_test_flat = flatten_and_convert([(times[0],) for times in test_true_times])\n",
    "s_times_true_test_flat = flatten_and_convert([(times[1],) for times in test_true_times])\n",
    "p_times_pred_test_flat = flatten_and_convert([(times[0],) for times in test_pred_times])\n",
    "s_times_pred_test_flat = flatten_and_convert([(times[1],) for times in test_pred_times])\n",
    "\n",
    "print(p_times_true_val_flat[0], p_times_true_val_flat[1], p_times_true_val_flat[2], p_times_true_val_flat[3])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Dividing all values in each array by 100\n",
    "p_times_true_train_flat_n = np.array(p_times_true_train_flat) / 100\n",
    "p_times_pred_train_flat_n = np.array(p_times_pred_train_flat) / 100\n",
    "s_times_true_train_flat_n = np.array(s_times_true_train_flat) / 100\n",
    "s_times_pred_train_flat_n = np.array(s_times_pred_train_flat) / 100\n",
    "\n",
    "p_times_true_val_flat_n = np.array(p_times_true_val_flat) / 100\n",
    "p_times_pred_val_flat_n = np.array(p_times_pred_val_flat) / 100\n",
    "s_times_true_val_flat_n = np.array(s_times_true_val_flat) / 100\n",
    "s_times_pred_val_flat_n = np.array(s_times_pred_val_flat) / 100\n",
    "\n",
    "p_times_true_test_flat_n = np.array(p_times_true_test_flat) / 100\n",
    "p_times_pred_test_flat_n = np.array(p_times_pred_test_flat) / 100\n",
    "s_times_true_test_flat_n = np.array(s_times_true_test_flat) / 100\n",
    "s_times_pred_test_flat_n = np.array(s_times_pred_test_flat) / 100\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_true_vs_predicted_with_deviation(true_data, pred_data, titles, wave_type):\n",
    "    \"\"\" Plot True vs. Predicted times for P or S waves across Train, Validation, and Test datasets. \"\"\"\n",
    "    colors = ['red', 'green', 'blue']  # Colors for Train, Validation, Test\n",
    "    labels = ['Train', 'Validation', 'Test']\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for true, pred, color, label in zip(true_data, pred_data, colors, labels):\n",
    "        true = np.array(true)\n",
    "        pred = np.array(pred)\n",
    "\n",
    "        # Plotting actual vs predicted\n",
    "        plt.scatter(true, pred, color=color, label=f'{label} Actual vs. Predicted', alpha=0.6)\n",
    "        plt.plot([true.min(), true.max()], [true.min(), true.max()], 'k--', lw=2)  # Line of perfect prediction\n",
    "        #plt.plot(true, true * 1.3, '--', color=color, lw=1)  # +30% deviation line\n",
    "        #plt.plot(true, true * 0.7, '--', color=color, lw=1)  # -30% deviation line\n",
    "        plt.plot(true, true + 3.0, '--', color=color, lw=1)  # +3 second deviation line\n",
    "        plt.plot(true, true - 3.0, '--', color=color, lw=1)  # -3 second deviation line\n",
    "\n",
    "\n",
    "    # Define the maximum range for ticks based on the data\n",
    "    max_time = max([t.max() for t in true] + [p.max() for p in pred])\n",
    "    major_ticks = np.arange(0, np.ceil(max_time) + 1, 1)  # Major ticks every 1 second\n",
    "    #minor_ticks = np.arange(0, np.ceil(max_time) + 0.1, 0.2)  # Minor ticks every 0.2 seconds\n",
    "\n",
    "    plt.xticks(major_ticks)\n",
    "    plt.yticks(major_ticks)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    #plt.minorticks_on()\n",
    "    #plt.grid(True, which='minor', linestyle='-', color='grey', linewidth=0.5)  # Thin grey lines for minor ticks\n",
    "\n",
    "\n",
    "    plt.xlabel('Actual Time (s)')\n",
    "    plt.ylabel('Predicted Time (s)')\n",
    "    #plt.title(f'True vs. Predicted {wave_type} Times with 30% Deviation')\n",
    "    plt.title(f'True vs. Predicted {wave_type} Times with -+3 Seconds Deviation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combined_true_vs_predicted_with_deviation(\n",
    "    [p_times_true_train_flat_n, p_times_true_val_flat_n, p_times_true_test_flat_n],\n",
    "    [ p_times_pred_train_flat_n, p_times_pred_val_flat_n, p_times_pred_test_flat_n],\n",
    "    [ 'Train','Validation', 'Test'],\n",
    "    'P'\n",
    ")\n",
    "\n",
    "plot_combined_true_vs_predicted_with_deviation(\n",
    "    [s_times_true_train_flat_n, s_times_true_val_flat_n, s_times_true_test_flat_n],\n",
    "    [s_times_pred_train_flat_n, s_times_pred_val_flat_n, s_times_pred_test_flat_n],\n",
    "    [ 'Train','Validation', 'Test'],\n",
    "    'S'\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
